{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# IMPORTS\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import tf2cv, cv2, PIL, os\n",
    "from tf2cv.model_provider import get_model\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Image\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# SETTINGS\n",
    "\n",
    "CLASSES = [\"airplane\", \"automobile\", \"bird\", \"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "GPUs = [d for d in tf.config.list_physical_devices() if \"GPU\" in d.device_type]\n",
    "DEVICE = tf.device(\"GPU\") if (len(GPUs) > 0) else tf.device(\"CPU\")\n",
    "\n",
    "DTYPE = \"float32\" # float64\n",
    "\n",
    "tf.keras.backend.set_floatx(DTYPE) # sets network layers to DTYPE\n",
    "\n",
    "BS = 64 # autoencoder batch size\n",
    "DIM = 32 # pixel dimensions, e.g. 32 for 32x32 color images\n",
    "\n",
    "\n",
    "# LOAD DATASET\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "xtrain = tf.convert_to_tensor(x_train.astype(DTYPE) / 255.)\n",
    "xtest = tf.convert_to_tensor(x_test.astype(DTYPE) / 255.)\n",
    "ytrain = tf.convert_to_tensor(y_train.flatten())\n",
    "ytest = tf.convert_to_tensor(y_test.flatten())\n",
    "\n",
    "\n",
    "def augment(imgs):\n",
    "    imgs = tf.image.rot90(imgs, np.random.randint(0,4))\n",
    "    imgs = tf.image.random_flip_left_right(imgs)\n",
    "    imgs = tf.image.random_flip_up_down(imgs)\n",
    "    imgs = tf.image.random_hue(imgs, 0.07)\n",
    "    imgs = tf.image.random_saturation(imgs, 0.7, 1.5)\n",
    "    imgs = tf.image.random_brightness(imgs, 0.05)\n",
    "    imgs = tf.image.random_contrast(imgs, 0.6, 1.2)\n",
    "    imgs = tf.clip_by_value(imgs, 0, 1)\n",
    "    return imgs\n",
    "\n",
    "def preprocess(imgs):\n",
    "    \"Normalizes images (according to https://github.com/osmr/imgclsmob/blob/master/examples/demo_tf2.py)\"\n",
    "    mean_rgb = tf.constant([0.485, 0.456, 0.406]) # CIFAR-10 RGB mean\n",
    "    std_rgb = tf.constant([0.229, 0.224, 0.225]) # CIFAR-10 RGB standard deviation\n",
    "    mean_rgb = tf.cast(mean_rgb, DTYPE)\n",
    "    std_rgb = tf.cast(std_rgb, DTYPE)\n",
    "    return (imgs - mean_rgb)/std_rgb\n",
    "#     return tf.clip_by_value((imgs - mean_rgb) / std_rgb, 0, 1)\n",
    "\n",
    "def undo_preprocess(imgs):\n",
    "    \"restores preprocessed images to original state\"\n",
    "    mean_rgb = tf.constant([0.485, 0.456, 0.406]) # CIFAR-10 RGB mean\n",
    "    std_rgb = tf.constant([0.229, 0.224, 0.225]) # CIFAR-10 RGB standard deviation\n",
    "    mean_rgb = tf.cast(mean_rgb, DTYPE)\n",
    "    std_rgb = tf.cast(std_rgb, DTYPE)\n",
    "    return imgs*std_rgb + mean_rgb\n",
    "#     return tf.clip_by_value(imgs*std_rgb + mean_rgb, 0, 1)\n",
    "\n",
    "def evaluate(model, imgs, labels, loss_fn=tf.keras.losses.CategoricalCrossentropy(), preproc=True):\n",
    "    \"Returns loss and predictions\"\n",
    "    if preproc:\n",
    "        imgs = preprocess(imgs)\n",
    "    preds = tf.nn.softmax(model(imgs))\n",
    "    if labels.shape[-1] != len(CLASSES):\n",
    "        final_preds = tf.argmax(preds, axis=1)\n",
    "        final_preds = tf.cast(final_preds, labels.dtype)\n",
    "        labels = tf.one_hot(labels, depth=len(CLASSES), axis=1)\n",
    "    loss = loss_fn(labels, preds)\n",
    "    return loss, final_preds\n",
    "\n",
    "def perturb(imgs, labels, model, loss_fn=tf.keras.losses.CategoricalCrossentropy()):\n",
    "    \"creates a perturbation (as a np.array) for a given image, label, and model\"\n",
    "    with tf.GradientTape() as g:\n",
    "        g.watch(imgs)\n",
    "        preds = tf.nn.softmax(model(imgs))\n",
    "        loss = loss_fn(labels, preds)\n",
    "        grad = g.gradient(loss, imgs)\n",
    "        grad = grad if grad is not None else tf.zeros(imgs.shape)\n",
    "    return tf.sign(grad)\n",
    "\n",
    "class Attack:\n",
    "    def __init__(self, model, loss_fn=None, epsilon=8, target=None, preproc=False):\n",
    "        \"\"\"\n",
    "        model: tf model\n",
    "        loss_fn: tf loss function or None (default: CategoricalCrossentropy)\n",
    "        epsilon: maximum image noise perturbation within [0,255]\n",
    "        target: int (targeted) or None (untargeted)\n",
    "        \"\"\"\n",
    "        assert type(target) == int or target == None\n",
    "        assert type(loss_fn) != str\n",
    "        assert epsilon < 255 and epsilon >= 1\n",
    "        \n",
    "        self.epsilon = epsilon / 255.\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn if loss_fn is not None else tf.keras.losses.CategoricalCrossentropy()\n",
    "        self.target = target\n",
    "        self.preproc = preproc\n",
    "\n",
    "    def FGSM(self, imgs, labels):\n",
    "        \"FGSM attack; inputs: tf tensors\"\n",
    "        if self.preproc:\n",
    "            imgs = preprocess(imgs)\n",
    "        if type(self.target) == int:\n",
    "            labels = tf.constant([self.target]*imgs.shape[0])\n",
    "        if labels.shape[-1] != len(CLASSES):\n",
    "            labels = tf.one_hot(labels, depth=len(CLASSES), axis=1)\n",
    "\n",
    "        noise = perturb(imgs, labels, self.model, self.loss_fn)\n",
    "        noise = tf.clip_by_value(noise, -1, 1)\n",
    "        adv_imgs = (imgs + self.epsilon*noise) if self.target is None else (imgs - self.epsilon*noise)\n",
    "        adv_imgs = tf.clip_by_value(adv_imgs, 0, 1)\n",
    "        if self.preproc:\n",
    "            adv_imgs = undo_preprocess(adv_imgs)\n",
    "        return adv_imgs\n",
    "    \n",
    "    def PGD(self, imgs, labels, learning_rate=0.01, steps=10, random_init=True):\n",
    "        \"PGD attack; inputs: tf tensors\"\n",
    "        if learning_rate >= 1 and learning_rate < 255:\n",
    "            learning_rate = learning_rate / 255.\n",
    "        if type(self.target) == int:\n",
    "            labels = tf.constant([self.target]*imgs.shape[0])\n",
    "        if labels.shape[-1] != len(CLASSES):\n",
    "            labels = tf.one_hot(labels, depth=len(CLASSES), axis=1)\n",
    "\n",
    "        if self.preproc:\n",
    "            imgs = preprocess(imgs)\n",
    "        x = imgs\n",
    "        if random_init:\n",
    "            init_noise = tf.random.uniform(imgs.shape, -self.epsilon, self.epsilon)\n",
    "            init_noise = tf.cast(init_noise, x.dtype)\n",
    "            x += init_noise\n",
    "            x = tf.clip_by_value(x, 0, 1)\n",
    "\n",
    "        for i in range(steps):\n",
    "            noise = perturb(x, labels, self.model, self.loss_fn)\n",
    "            noise = tf.clip_by_value(noise, -1, 1)\n",
    "\n",
    "            if type(self.target) == int:\n",
    "                x -= learning_rate * noise\n",
    "            else:\n",
    "                x += learning_rate * noise\n",
    "            x = tf.clip_by_value(x, imgs - self.epsilon, imgs + self.epsilon)\n",
    "            x = tf.clip_by_value(x, 0, 1)\n",
    "        if self.preproc:\n",
    "            x = undo_preprocess(x)\n",
    "        return x\n",
    "    \n",
    "class Autoencoder(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(DIM, DIM, 3)),\n",
    "            tf.keras.layers.Conv2D(int(DIM/2), kernel_size=3, activation='relu', padding='same', strides=2),\n",
    "            tf.keras.layers.Conv2D(int(DIM/4), kernel_size=3, activation='relu', padding='same', strides=2),\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2DTranspose(int(DIM/4), kernel_size=3, activation='relu', padding='same', strides=2),\n",
    "            tf.keras.layers.Conv2DTranspose(int(DIM/2), kernel_size=3, activation='relu', padding='same', strides=2),\n",
    "            tf.keras.layers.Conv2D(3, kernel_size=3, activation='sigmoid', padding='same')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "    def summary(self, line_length=None, positions=None, print_fn=None):\n",
    "        self.encoder.summary(line_length, positions, print_fn)\n",
    "        self.decoder.summary(line_length, positions, print_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'resnet1202_cifar10',\n",
    "    'preresnet1202_cifar10',\n",
    "    'resnext272_1x64d_cifar10',\n",
    "    'resnext272_2x32d_cifar10',\n",
    "    'seresnet542bn_cifar10',\n",
    "    'sepreresnet542bn_cifar10',\n",
    "    'pyramidnet236_a220_bn_cifar10',\n",
    "    'pyramidnet272_a200_bn_cifar10',\n",
    "    'densenet250_k24_bc_cifar10'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'resnet20_cifar10',\n",
    "    'resnet56_cifar10',\n",
    "    'resnet110_cifar10',\n",
    "    'resnet164bn_cifar10',\n",
    "    'resnet272bn_cifar10',\n",
    "    'resnet542bn_cifar10',\n",
    "    'resnet1202_cifar10',\n",
    "    'preresnet20_cifar10',\n",
    "    'preresnet56_cifar10',\n",
    "    'preresnet110_cifar10',\n",
    "    'preresnet164bn_cifar10',\n",
    "    'preresnet272bn_cifar10',\n",
    "    'preresnet542bn_cifar10',\n",
    "    'preresnet1202_cifar10',\n",
    "    'resnext20_1x64d_cifar10',\n",
    "    'resnext20_2x32d_cifar10',\n",
    "    'resnext20_2x64d_cifar10',\n",
    "    'resnext20_4x16d_cifar10',\n",
    "    'resnext20_4x32d_cifar10',\n",
    "    'resnext20_8x8d_cifar10',\n",
    "    'resnext20_8x16d_cifar10',\n",
    "    'resnext20_16x4d_cifar10',\n",
    "    'resnext20_16x8d_cifar10',\n",
    "    'resnext20_32x2d_cifar10',\n",
    "    'resnext20_32x4d_cifar10',\n",
    "    'resnext20_64x1d_cifar10',\n",
    "    'resnext20_64x2d_cifar10',\n",
    "    'resnext29_32x4d_cifar10',\n",
    "    'resnext29_16x64d_cifar10',\n",
    "    'resnext56_1x64d_cifar10',\n",
    "    'resnext56_2x32d_cifar10',\n",
    "    'resnext56_4x16d_cifar10',\n",
    "    'resnext56_8x8d_cifar10',\n",
    "    'resnext56_16x4d_cifar10',\n",
    "    'resnext56_32x2d_cifar10',\n",
    "    'resnext56_64x1d_cifar10',\n",
    "    'resnext272_1x64d_cifar10',\n",
    "    'resnext272_2x32d_cifar10',\n",
    "    'seresnet20_cifar10',\n",
    "    'seresnet56_cifar10',\n",
    "    'seresnet110_cifar10',\n",
    "    'seresnet164bn_cifar10',\n",
    "    'seresnet272bn_cifar10',\n",
    "    'seresnet542bn_cifar10',\n",
    "    'sepreresnet20_cifar10',\n",
    "    'sepreresnet56_cifar10',\n",
    "    'sepreresnet110_cifar10',\n",
    "    'sepreresnet164bn_cifar10',\n",
    "    'sepreresnet272bn_cifar10',\n",
    "    'sepreresnet542bn_cifar10',\n",
    "    'pyramidnet110_a48_cifar10',\n",
    "    'pyramidnet110_a84_cifar10',\n",
    "    'pyramidnet110_a270_cifar10',\n",
    "    'pyramidnet164_a270_bn_cifar10',\n",
    "    'pyramidnet200_a240_bn_cifar10',\n",
    "    'pyramidnet236_a220_bn_cifar10',\n",
    "    'pyramidnet272_a200_bn_cifar10',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'resnet20_cifar10',\n",
    "    'resnet56_cifar10',\n",
    "    'resnet110_cifar10',\n",
    "    'preresnet20_cifar10',\n",
    "    'preresnet56_cifar10',\n",
    "    'preresnet110_cifar10',\n",
    "    'seresnet20_cifar10',\n",
    "    'seresnet56_cifar10',\n",
    "    'seresnet110_cifar10',\n",
    "    'sepreresnet20_cifar10',\n",
    "    'sepreresnet56_cifar10',\n",
    "    'sepreresnet110_cifar10',\n",
    "    'resnext20_32x2d_cifar10',\n",
    "    'resnext20_32x4d_cifar10',\n",
    "    'resnext20_64x1d_cifar10',\n",
    "    'resnext20_64x2d_cifar10',\n",
    "    'resnext29_32x4d_cifar10',\n",
    "    'resnext29_16x64d_cifar10',\n",
    "    'resnext56_1x64d_cifar10',\n",
    "    'resnext56_2x32d_cifar10',\n",
    "    'resnext56_4x16d_cifar10',\n",
    "    'resnext56_8x8d_cifar10',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0  resnet20_cifar10     0.7909     5.602394104003906\n",
    "    1  resnet56_cifar10     0.7909     15.917900562286377\n",
    "    2  resnet110_cifar10     0.8033     31.530543088912964\n",
    "    3  preresnet20_cifar10     0.7979     5.553314208984375\n",
    "    4  preresnet56_cifar10     0.8159     15.875879049301147\n",
    "    5  preresnet110_cifar10     0.8242     31.465455055236816\n",
    "    6  seresnet20_cifar10     0.7788     6.165999889373779\n",
    "    7  seresnet56_cifar10     0.8041     17.61270236968994\n",
    "    8  seresnet110_cifar10     0.8145     34.87532997131348\n",
    "    9  sepreresnet20_cifar10     0.7675     6.213705778121948\n",
    "    10  sepreresnet56_cifar10     0.8213     17.639922618865967\n",
    "    11  sepreresnet110_cifar10     0.7995     34.84875535964966\n",
    "    12  pyramidnet110_a48_cifar10     0.7534     52.499168395996094\n",
    "    13  pyramidnet110_a84_cifar10     0.8044     75.8461856842041\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'preresnet110_cifar10',\n",
    "    'sepreresnet56_cifar10',\n",
    "    'sepreresnet110_cifar10',\n",
    "    'preresnet56_cifar10',\n",
    "    'resnet110_cifar10',\n",
    "#     'preresnet164bn_cifar10',\n",
    "#     'preresnet272bn_cifar10',\n",
    "#     'preresnet542bn_cifar10',\n",
    "#     'sepreresnet164bn_cifar10',\n",
    "#     'sepreresnet272bn_cifar10',\n",
    "#     'sepreresnet542bn_cifar10',\n",
    "#     'resnext20_32x2d_cifar10',\n",
    "#     'resnext20_32x4d_cifar10',\n",
    "#     'resnext20_64x1d_cifar10',\n",
    "#     'resnext20_64x2d_cifar10',\n",
    "#     'resnext29_32x4d_cifar10',\n",
    "#     'resnext29_16x64d_cifar10',\n",
    "#     'resnext56_1x64d_cifar10',\n",
    "#     'resnext56_2x32d_cifar10',\n",
    "#     'resnext56_4x16d_cifar10',\n",
    "#     'resnext56_8x8d_cifar10',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"sepreresnet56_cifar10\", \"resnet110_cifar10\"] # winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepreresnet56_cifar10\n",
      "resnet110_cifar10\n",
      "Time: 7.314396858215332\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "models = []\n",
    "for name in model_names:\n",
    "    print(name)\n",
    "    model = get_model(name, pretrained=True)\n",
    "    model.trainable = False\n",
    "    models.append(model)\n",
    "print(\"Time:\", time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifarse_pre_res_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (Sequential)        (1, 1, 1, 64)             865919    \n",
      "_________________________________________________________________\n",
      "output1 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 866,569\n",
      "Trainable params: 0\n",
      "Non-trainable params: 866,569\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar_res_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (Sequential)        (1, 1, 1, 64)             1738352   \n",
      "_________________________________________________________________\n",
      "output1 (Dense)              multiple                  650       \n",
      "=================================================================\n",
      "Total params: 1,739,002\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,739,002\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models[1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR AUTOENCODER TRAINING\n",
    "\n",
    "fgsm_train_0 = np.load(\"fgsm_train_0.npy\")\n",
    "pgd_train_0 = np.load(\"pgd_train_0.npy\")\n",
    "\n",
    "fgsm_train_1 = np.load(\"fgsm_train_1.npy\")\n",
    "pgd_train_1 = np.load(\"pgd_train_1.npy\")\n",
    "\n",
    "fgsm_train_2 = np.load(\"fgsm_train_2.npy\")\n",
    "pgd_train_2 = np.load(\"pgd_train_2.npy\")\n",
    "\n",
    "fgsm_train_3 = np.load(\"fgsm_train_3.npy\")\n",
    "pgd_train_3 = np.load(\"pgd_train_3.npy\")\n",
    "\n",
    "fgsm_train_4 = np.load(\"fgsm_train_4.npy\")\n",
    "pgd_train_4 = np.load(\"pgd_train_4.npy\")\n",
    "\n",
    "fgsm_train = np.vstack([fgsm_train_0, fgsm_train_1, fgsm_train_2, fgsm_train_3, fgsm_train_4])\n",
    "pgd_train = np.vstack([pgd_train_0, pgd_train_1, pgd_train_2, pgd_train_3, pgd_train_4])\n",
    "\n",
    "fgsm_test = np.load(\"fgsm_test.npy\")\n",
    "pgd_test = np.load(\"pgd_test.npy\")\n",
    "\n",
    "all_train = np.vstack([xtrain, fgsm_train, pgd_train])\n",
    "all_train_target = np.vstack([xtrain, xtrain, xtrain])\n",
    "\n",
    "fgsm_train = tf.convert_to_tensor(fgsm_train.astype(DTYPE))\n",
    "pgd_train = tf.convert_to_tensor(pgd_train.astype(DTYPE))\n",
    "fgsm_test = tf.convert_to_tensor(fgsm_test.astype(DTYPE))\n",
    "pgd_test = tf.convert_to_tensor(pgd_test.astype(DTYPE))\n",
    "\n",
    "all_train = tf.convert_to_tensor(all_train.astype(DTYPE))\n",
    "all_train_target = tf.convert_to_tensor(all_train_target.astype(DTYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR RESNET FINE TUNING\n",
    "\n",
    "fgsm_train_dec_0 = np.load(\"fgsm_train_dec_0.npy\")\n",
    "pgd_train_dec_0 = np.load(\"pgd_train_dec_0.npy\")\n",
    "orig_train_dec_0 = np.load(\"orig_train_dec_0.npy\")\n",
    "\n",
    "fgsm_train_dec_1 = np.load(\"fgsm_train_dec_1.npy\")\n",
    "pgd_train_dec_1 = np.load(\"pgd_train_dec_1.npy\")\n",
    "orig_train_dec_1 = np.load(\"orig_train_dec_1.npy\")\n",
    "\n",
    "fgsm_train_dec_2 = np.load(\"fgsm_train_dec_2.npy\")\n",
    "pgd_train_dec_2 = np.load(\"pgd_train_dec_2.npy\")\n",
    "orig_train_dec_2 = np.load(\"orig_train_dec_2.npy\")\n",
    "\n",
    "fgsm_train_dec_3 = np.load(\"fgsm_train_dec_3.npy\")\n",
    "pgd_train_dec_3 = np.load(\"pgd_train_dec_3.npy\")\n",
    "orig_train_dec_3 = np.load(\"orig_train_dec_3.npy\")\n",
    "\n",
    "fgsm_train_dec_4 = np.load(\"fgsm_train_dec_4.npy\")\n",
    "pgd_train_dec_4 = np.load(\"pgd_train_dec_4.npy\")\n",
    "orig_train_dec_4 = np.load(\"orig_train_dec_4.npy\")\n",
    "\n",
    "fgsm_train_dec = np.vstack([fgsm_train_dec_0, fgsm_train_dec_1, fgsm_train_dec_2, fgsm_train_dec_3, fgsm_train_dec_4])\n",
    "pgd_train_dec = np.vstack([pgd_train_dec_0, pgd_train_dec_1, pgd_train_dec_2, pgd_train_dec_3, pgd_train_dec_4])\n",
    "orig_train_dec = np.vstack([orig_train_dec_0, orig_train_dec_1, orig_train_dec_2, orig_train_dec_3, orig_train_dec_4])\n",
    "\n",
    "dec_orig_test = np.load(\"dec_orig_test.npy\")\n",
    "dec_fgsm_test = np.load(\"dec_fgsm_test.npy\")\n",
    "dec_pgd_test = np.load(\"dec_pgd_test.npy\")\n",
    "\n",
    "all_train = np.vstack([xtrain, fgsm_train, pgd_train, fgsm_train_dec, pgd_train_dec])\n",
    "all_train_target = np.hstack([ytrain, ytrain, ytrain, ytrain, ytrain])\n",
    "\n",
    "fgsm_train_dec = tf.convert_to_tensor(fgsm_train_dec.astype(DTYPE))\n",
    "pgd_train_dec = tf.convert_to_tensor(pgd_train_dec.astype(DTYPE))\n",
    "dec_orig_test = tf.convert_to_tensor(dec_orig_test.astype(DTYPE))\n",
    "dec_fgsm_test = tf.convert_to_tensor(dec_fgsm_test.astype(DTYPE))\n",
    "dec_pgd_test = tf.convert_to_tensor(dec_pgd_test.astype(DTYPE))\n",
    "\n",
    "all_train = tf.convert_to_tensor(all_train.astype(DTYPE))\n",
    "all_train_target = tf.convert_to_tensor(all_train_target.astype(DTYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINE TUNE (AFTER 3 EPOCHS)\n",
    "\n",
    "all_train = np.vstack([xtrain, fgsm_train_dec, pgd_train_dec])\n",
    "all_train_target = np.hstack([ytrain, ytrain, ytrain])\n",
    "\n",
    "\n",
    "all_train = tf.convert_to_tensor(all_train.astype(DTYPE))\n",
    "all_train_target = tf.convert_to_tensor(all_train_target.astype(DTYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FINE TUNE (AFTER 3+1+2 EPOCHS)\n",
    "\n",
    "all_train = np.vstack([xtrain, orig_train_dec, fgsm_train_dec, pgd_train_dec])\n",
    "all_train_target = np.hstack([ytrain, ytrain, ytrain, ytrain])\n",
    "\n",
    "all_train = tf.convert_to_tensor(all_train.astype(DTYPE))\n",
    "all_train_target = tf.convert_to_tensor(all_train_target.astype(DTYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 8)           1160      \n",
      "=================================================================\n",
      "Total params: 1,608\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,608\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 8)         584       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 3)         435       \n",
      "=================================================================\n",
      "Total params: 2,187\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,187\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = tf.keras.models.load_model(\"models/autoencoder_protection\")\n",
    "autoencoder.trainable = False\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE time: 0.640149\n",
      "\n",
      "0  preresnet110_cifar10    Original: 0.9598 --> 0.8242   (time: 31.29)\n",
      "0  preresnet110_cifar10    FGSM: 0.4774 --> 0.749       (time: 31.36)\n",
      "0  preresnet110_cifar10    PGD: 0.3578 --> 0.7843        (time: 31.42)\n",
      "1  sepreresnet56_cifar10    Original: 0.9532 --> 0.8213   (time: 17.45)\n",
      "1  sepreresnet56_cifar10    FGSM: 0.4711 --> 0.7411       (time: 17.45)\n",
      "1  sepreresnet56_cifar10    PGD: 0.2966 --> 0.7835        (time: 17.47)\n",
      "2  sepreresnet110_cifar10    Original: 0.9535 --> 0.7995   (time: 34.39)\n",
      "2  sepreresnet110_cifar10    FGSM: 0.5423 --> 0.7227       (time: 34.42)\n",
      "2  sepreresnet110_cifar10    PGD: 0.3987 --> 0.7615        (time: 34.42)\n",
      "3  preresnet56_cifar10    Original: 0.9543 --> 0.8159   (time: 15.93)\n",
      "3  preresnet56_cifar10    FGSM: 0.4309 --> 0.7363       (time: 15.92)\n",
      "3  preresnet56_cifar10    PGD: 0.3172 --> 0.7761        (time: 15.91)\n",
      "4  resnet110_cifar10    Original: 0.9625 --> 0.8033   (time: 31.72)\n",
      "4  resnet110_cifar10    FGSM: 0.4526 --> 0.724       (time: 31.72)\n",
      "4  resnet110_cifar10    PGD: 0.3116 --> 0.7655        (time: 31.75)\n"
     ]
    }
   ],
   "source": [
    "# CHECK EFFECTIVENESS\n",
    "\n",
    "# xtest = augment(xtest)\n",
    "# fgsm_test = augment(fgsm_test)\n",
    "# pgd_test = augment(pgd_test)\n",
    "\n",
    "t = time.time()\n",
    "enc_orig = autoencoder.encoder(xtest)\n",
    "dec_orig = autoencoder.decoder(enc_orig)\n",
    "t = time.time() - t\n",
    "print(f\"AE time: {t:2f}\\n\")\n",
    "\n",
    "enc_fgsm = autoencoder.encoder(fgsm_test)\n",
    "dec_fgsm = autoencoder.decoder(enc_fgsm)\n",
    "\n",
    "enc_pgd = autoencoder.encoder(pgd_test)\n",
    "dec_pgd = autoencoder.decoder(enc_pgd)\n",
    "\n",
    "i = 0\n",
    "for name, model in zip(model_names, models):\n",
    "    \n",
    "    loss, preds = evaluate(model, xtest, ytest)\n",
    "    orig = np.mean(preds == ytest)\n",
    "    t = time.time()\n",
    "    loss, preds = evaluate(model, dec_orig, ytest)\n",
    "    new = np.mean(preds == ytest)\n",
    "    t = time.time() - t\n",
    "    print(f\"{i}  {name}    Original: {orig} --> {new}   (time: {t:.2f})\")\n",
    "    \n",
    "    loss, preds = evaluate(model, fgsm_test, ytest)\n",
    "    orig = np.mean(preds == ytest)\n",
    "    t = time.time()\n",
    "    loss, preds = evaluate(model, dec_fgsm, ytest)\n",
    "    new = np.mean(preds == ytest)\n",
    "    t = time.time() - t\n",
    "    print(f\"{i}  {name}    FGSM: {orig} --> {new}       (time: {t:.2f})\")\n",
    "    \n",
    "    loss, preds = evaluate(model, pgd_test, ytest)\n",
    "    orig = np.mean(preds == ytest)\n",
    "    t = time.time()\n",
    "    loss, preds = evaluate(model, dec_pgd, ytest)\n",
    "    new = np.mean(preds == ytest)\n",
    "    t = time.time() - t\n",
    "    print(f\"{i}  {name}    PGD: {orig} --> {new}        (time: {t:.2f})\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backup model: Use sepreresnet56_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    0  resnet20_cifar10     0.7909     5.602394104003906\n",
    "    1  resnet56_cifar10     0.7909     15.917900562286377\n",
    "    2  resnet110_cifar10     0.8033     31.530543088912964\n",
    "    3  preresnet20_cifar10     0.7979     5.553314208984375\n",
    "    4  preresnet56_cifar10     0.8159     15.875879049301147\n",
    "    5  preresnet110_cifar10     0.8242     31.465455055236816\n",
    "    6  seresnet20_cifar10     0.7788     6.165999889373779\n",
    "    7  seresnet56_cifar10     0.8041     17.61270236968994\n",
    "    8  seresnet110_cifar10     0.8145     34.87532997131348\n",
    "    9  sepreresnet20_cifar10     0.7675     6.213705778121948\n",
    "    10  sepreresnet56_cifar10     0.8213     17.639922618865967\n",
    "    11  sepreresnet110_cifar10     0.7995     34.84875535964966\n",
    "    12  pyramidnet110_a48_cifar10     0.7534     52.499168395996094\n",
    "    13  pyramidnet110_a84_cifar10     0.8044     75.8461856842041\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet architecture:\n",
    "\n",
    "    1 - Stem    - Conv3x3|BN|Swish\n",
    "\n",
    "    2 - Blocks  - MBConv1, k3x3 \n",
    "                - MBConv6, k3x3 repeated 2 times\n",
    "                - MBConv6, k5x5 repeated 2 times\n",
    "                - MBConv6, k3x3 repeated 3 times\n",
    "                - MBConv6, k5x5 repeated 3 times\n",
    "                - MBConv6, k5x5 repeated 4 times\n",
    "                - MBConv6, k3x3\n",
    "                                totally 16 blocks\n",
    "\n",
    "    3 - Head    - Conv1x1|BN|Swish \n",
    "                - Pooling\n",
    "                - Dropout\n",
    "                - FC\n",
    "                \n",
    "        where Swish(x) = x * sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet20_cifar10 - time:  5.414407014846802 \n",
      "\n",
      "  (Test Accuracy) With autoencoder protection:\n",
      "    Regular: 0.9384 --> 0.7909\n",
      "  FGSM: 0.2437 --> 0.6678\n",
      "  PGD: 0.0013 --> 0.7284\n",
      "\n",
      "resnet56_cifar10 - time:  15.432801961898804 \n",
      "\n",
      "  (Test Accuracy) With autoencoder protection:\n",
      "    Regular: 0.9524 --> 0.7909\n",
      "  FGSM: 0.4109 --> 0.7092\n",
      "  PGD: 0.2537 --> 0.7476\n",
      "\n",
      "resnet110_cifar10 - time:  31.615257501602173 \n",
      "\n",
      "  (Test Accuracy) With autoencoder protection:\n",
      "    Regular: 0.9625 --> 0.8033\n",
      "  FGSM: 0.4526 --> 0.724\n",
      "  PGD: 0.3116 --> 0.7655\n",
      "\n",
      "preresnet20_cifar10 - time:  5.542132377624512 \n",
      "\n",
      "  (Test Accuracy) With autoencoder protection:\n",
      "    Regular: 0.9334 --> 0.7979\n",
      "  FGSM: 0.3481 --> 0.7086\n",
      "  PGD: 0.1648 --> 0.7515\n",
      "\n",
      "preresnet56_cifar10 - time:  15.8715341091156 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-687827faa0e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name} - time: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  (Test Accuracy) With autoencoder protection:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-cf4ac54ef113>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, imgs, labels, loss_fn, preproc)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mfinal_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tf2cv/models/preresnet_cifar.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    370\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    370\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m    385\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 386\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tf2cv/models/preresnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pre_activ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_identity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pre_activ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tf2cv/models/preresnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pre_activ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pre_activ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tf2cv/models/common.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_preact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0mx_pre_activ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_preact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pre_activ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tf2cv/models/common.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation_rate\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1148\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2589\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2590\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2591\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2592\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2593\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    936\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CHECK EFFECTIVENESS\n",
    "\n",
    "# xtest = augment(xtest)\n",
    "# fgsm_test = augment(fgsm_test)\n",
    "# pgd_test = augment(pgd_test)\n",
    "\n",
    "enc_orig = autoencoder.encoder(xtest)\n",
    "dec_orig = autoencoder.decoder(enc_orig)\n",
    "\n",
    "enc_fgsm = autoencoder.encoder(fgsm_test)\n",
    "dec_fgsm = autoencoder.decoder(enc_fgsm)\n",
    "\n",
    "enc_pgd = autoencoder.encoder(pgd_test)\n",
    "dec_pgd = autoencoder.decoder(enc_pgd)\n",
    "\n",
    "for name, model in zip(model_names, models):\n",
    "\n",
    "    t = time.time()\n",
    "    loss, preds = evaluate(model, xtest, ytest)\n",
    "    orig = np.mean(preds == ytest)\n",
    "    print(f\"{name} - time: \",time.time() - t,\"\\n\")\n",
    "    loss, preds = evaluate(model, dec_orig, ytest)\n",
    "    new = np.mean(preds == ytest)\n",
    "    print(\"  (Test Accuracy) With autoencoder protection:\")\n",
    "    print(f\"    Regular: {orig} --> {new}\")\n",
    "\n",
    "    loss, preds = evaluate(model, fgsm_test, ytest)\n",
    "    orig = np.mean(preds == ytest)\n",
    "    loss, preds = evaluate(model, dec_fgsm, ytest)\n",
    "    new = np.mean(preds == ytest)\n",
    "    print(f\"  FGSM: {orig} --> {new}\")\n",
    "\n",
    "    loss, preds = evaluate(model, pgd_test, ytest)\n",
    "    orig = np.mean(preds == ytest)\n",
    "    loss, preds = evaluate(model, dec_pgd, ytest)\n",
    "    new = np.mean(preds == ytest)\n",
    "    print(f\"  PGD: {orig} --> {new}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
